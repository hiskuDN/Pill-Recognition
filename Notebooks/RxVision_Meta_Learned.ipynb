{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-woodbury/RxVision/blob/master/Notebooks/RxVision_Technical_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1T15isJMwbP3"
      },
      "source": [
        "# RxVision\n",
        "\n",
        "RxVision is a image recognition model for identifying medications. The goal is to create a fast, reliable, and scalable solution for clinicians, dispensing pharmacies, and patients to get real-time identification of a capsule or tablet. \n",
        "\n",
        "This first version uses a convolutional neural network to distinguish images of medications into 15 classes, in this case specific medications by their National Drug Code (NDC). \n",
        "\n",
        "The 15 drugs selected for training were chosen for their ability to be evaluated in the real-world; patients (my friends and family) provided (willingly) images of their medications in their hand or on their counter to showcase how a patient would use this model in reality. Each drug class provided 30 NIH images for training and validation and 1 real-world image for testing. \n",
        "\n",
        "The training images were acquired from the NIH dataset, which houses over 130,000 images of 4300+ distinct medications. On average, each medication has 29 images that can be used for training, but there are about 250 with over 50. images. I would have preferred to train on those medications, but no real-world images were available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IaeOc9Qu5QkJ"
      },
      "source": [
        "# Model Prep\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EvVMSdLu5WeP"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XBpY0iZD5HCS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rawpy in c:\\users\\mehret\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.18.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\mehret\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rawpy) (1.23.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from IPython.display import Image\n",
        "from ftplib import FTP #needed to make the request to the server\n",
        "\n",
        "# packages for processing images\n",
        "! pip install rawpy\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import rawpy\n",
        "import imageio\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "import os, shutil, sys #required for moving files\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#!{sys.executable} -m pip install opencv-python\n",
        "\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import tensorflow.keras \n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import multiprocessing\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, GridSearchCV, validation_curve \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, r2_score, recall_score, precision_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, validation_curve\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#from tensorflow.keras import get_default_graph\n",
        "\n",
        "from pandas_datareader import data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import urllib.request, json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# This code has been tested with TensorFlow 1.6\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "np.random.seed(123)\n",
        "\n",
        "# Transfer learning with VGG16\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "import random \n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kWgAgbA4QlgN"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aSLt3wPFcrXc"
      },
      "outputs": [],
      "source": [
        "def model_scores(model):\n",
        "  '''Return validation accuracy and real-world accuracy after evaluating provided model'''\n",
        "  model_val_results = model.evaluate(val_generator)\n",
        "  modelacc = model_val_results[1]\n",
        "  model_rw_results = model.evaluate(realworld_generator)\n",
        "  modelrw = model_rw_results[1]\n",
        "  print('\\nValidation Accuracy: ' + str(int(modelacc*100)) + '%' + '\\nReal-world Accuracy: ' + str(int(modelrw*100)) + '%')\n",
        "\n",
        "def model_acc_val_plot(model):\n",
        "  '''Return train and validation loss and accuracy plots from hist log'''\n",
        "  class_size =  int(val_generator.samples / len(val_generator.class_indices))\n",
        "  acc = hist['acc']\n",
        "  val_acc = hist['val_acc']\n",
        "\n",
        "  loss = hist['loss']\n",
        "  val_loss = hist['val_loss']\n",
        "\n",
        "  epochs_range = range(EPOCHS)\n",
        "\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(range(0,len(hist)), acc, label='Training Accuracy')\n",
        "  plt.plot(range(0,len(hist)), val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.plot(range(0,len(hist)), loss, label='Training Loss')\n",
        "  plt.plot(range(0,len(hist)), val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.savefig('../Images/{}_AccLoss.png'.format(model.name))\n",
        "  plt.show()\n",
        "\n",
        "def model_confusion(model):\n",
        "  '''Return a confusion matrix for predictions made from evaluating the proviced model'''\n",
        "  labels = list((val_generator.class_indices).values())\n",
        "  pred = model.predict(val_generator)\n",
        "  y_pred=np.argmax(pred,axis=1)\n",
        "  y_true = val_generator.classes\n",
        "\n",
        "  cf_matrix = metrics.confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(8,6.75))  \n",
        "  pal = sns.light_palette(\"#ffab40\", as_cmap=True)\n",
        "  sns.heatmap(cf_matrix, annot=True,cmap=pal,ax=ax)\n",
        "  plt.ylabel('Class Actual', fontweight='bold')\n",
        "  plt.xlabel('Class Predicted', fontweight='bold')\n",
        "  plt.title('../Images/{}_Confusion Matrix'.format(model.name), fontweight='bold', loc='left')\n",
        "  plt.savefig('../Images/{}_conf'.format(model.name))\n",
        "\n",
        "def predict_plot(model):\n",
        "  '''\n",
        "  Return an image plot with class, number of correct predictions,\n",
        "  and predicted classes (ordered by descending frequency)\n",
        "  '''\n",
        "  labels = list((val_generator.class_indices).values())\n",
        "  pred = model.predict(val_generator)\n",
        "  y_pred=np.argmax(pred,axis=1)\n",
        "  y_true = val_generator.classes\n",
        "  class_size =  int(val_generator.samples / len(val_generator.class_indices))\n",
        "  dfx = df[df.TYPE == 'MC_COOKED_CALIBRATED_V1.2']\n",
        "  samplesdfx = dfx.groupby(['NDC']).min().reset_index()\n",
        "  sampleslist2 = samplesdfx.FILE.tolist()\n",
        "  #len(sampleslist2)\n",
        "\n",
        "  samplefiles = []\n",
        "  for image in sampleslist2:\n",
        "      smplsplt = image.split('/')\n",
        "      keep = smplsplt[-1]\n",
        "      keep = keep[:-4]\n",
        "      keep= keep +('.JPG')\n",
        "      samplefiles.append(keep)\n",
        "\n",
        "      \n",
        "  #for file in os.listdir():\n",
        "  drgimg = os.listdir()\n",
        "  images = []\n",
        "  for file in samplefiles:\n",
        "      data = plt.imread(file)\n",
        "      images.append(data)\n",
        "  plt.figure(figsize=(15,15))\n",
        "  columns = 5\n",
        "\n",
        "  for i, image in enumerate(images): # iterate through the images in the array 'images'\n",
        "      k = i * class_size\n",
        "      j = (i + 1) * class_size\n",
        "      trues = int(y_true[k:j].mean())\n",
        "      preds = list(y_pred[k:j]).count(trues)\n",
        "      lst = list(y_pred[k:j])\n",
        "      preddict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0}\n",
        "      for pred in lst:\n",
        "          preddict[pred] +=1\n",
        "      preddict = {k: v for k, v in sorted(preddict.items(), key=lambda item: item[1], reverse=True)}\n",
        "      for k, v in list(preddict.items()):\n",
        "          if v == 0:\n",
        "              del preddict[k]\n",
        "      predlist = list(preddict.keys())\n",
        "      dname = df.DRUG[df.FILENAME.str.contains(samplefiles[i][:-4])].tolist()[0] # get the drug name from the df for the image in index i \n",
        "      dndc = df.NDC[df.FILENAME.str.contains(samplefiles[i][:-4])].tolist()[0] # get the NDC from the df for the image in index i \n",
        "      title = '[' + str(i) + '] ' + ' ' + dname + '\\nCorrect: ' + str(preds) + '\\nPreds: ' +  ', '.join(map(str,predlist)) # title for each subplot: class, drug name, and NDC\n",
        "      plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "      plt.suptitle('RxID15 Classes',fontweight='bold',fontsize='large', color= '#ffab40')\n",
        "      plt.subplots_adjust(hspace=0.2,wspace=0.25, top=.9, bottom=.2) # i believe this is the subplots spacing from each other and within the plot\n",
        "      plt.margins(tight=True) # not sure which margins this is impacting\n",
        "      plt.title(title,fontweight='semibold',fontsize='10')\n",
        "      plt.imshow(image)\n",
        "      plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "      plt.savefig('/content/drive/My Drive/RxID2/Images/{}_predictions.jpg'.format(model.name),format='jpg',quality=95,dpi=300, bbox='tight',pad_inches = 0) # bbox has always given me the output i wanted...\n",
        "  %cd ../..\n",
        "\n",
        "def real_world_predicts(model):\n",
        "  '''Return predicted classes for real world images using provided model'''\n",
        "  pred = model.predict(realworld_generator)\n",
        "  y_pred=np.argmax(pred,axis=1)\n",
        "  print('\\nReal-world predictions 0-14: ', y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_MbWoNch6MQz"
      },
      "source": [
        "## Data Selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nbtCuc0yGVWY"
      },
      "source": [
        "\n",
        "The dataset includes a [readme](ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Pills/AAREADME) that outlines the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "rb3m-JxB5lJV",
        "outputId": "071a7c75-10cb-4d11-b3c7-3b043abeca0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NDC</th>\n",
              "      <th>PART_#</th>\n",
              "      <th>FILE</th>\n",
              "      <th>TYPE</th>\n",
              "      <th>DRUG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002322730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc69/images/CLLLLUPGIX7J8MP1WWQ9W...</td>\n",
              "      <td>C3PI_Reference</td>\n",
              "      <td>STRATTERA 10MG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002322730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc98/images/PRNJ-AXZIQ!HUQKJJBP_D...</td>\n",
              "      <td>C3PI_Reference</td>\n",
              "      <td>STRATTERA 10MG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00002322730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc10/images/79U-YY6M1UUR6F127ZMAC...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>STRATTERA 10MG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00002322730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc11/images/7WVFV5H74!ELFNQ_GUH92...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>STRATTERA 10MG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00002322730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc20/images/B4CH0R9B7PEQ6GORRX-8X...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>STRATTERA 10MG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133769</th>\n",
              "      <td>99207046730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc103/images/TY5OVXLLOXV6H4I1TDVT...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SOLODYN 105 MG TAB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133770</th>\n",
              "      <td>99207046730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc31/images/BEIR3XK38EMGSDOZTWMUK...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SOLODYN 105 MG TAB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133771</th>\n",
              "      <td>99207046730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc69/images/CLJ1W40OS0XG5H6IVYT!N...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SOLODYN 105 MG TAB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133772</th>\n",
              "      <td>99207046730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc77/images/CSUHWDZ!XAZSEJHDANMFR...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SOLODYN 105 MG TAB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133773</th>\n",
              "      <td>99207046730</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc23/images/B7P0-2BHT7T88IHB4E1EE...</td>\n",
              "      <td>MC_SPL_SPLIMAGE_V3.0</td>\n",
              "      <td>SOLODYN 105 MG TAB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133774 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                NDC  PART_#  ...                       TYPE                DRUG\n",
              "0       00002322730       1  ...             C3PI_Reference      STRATTERA 10MG\n",
              "1       00002322730       1  ...             C3PI_Reference      STRATTERA 10MG\n",
              "2       00002322730       1  ...                  C3PI_Test      STRATTERA 10MG\n",
              "3       00002322730       1  ...                  C3PI_Test      STRATTERA 10MG\n",
              "4       00002322730       1  ...                  C3PI_Test      STRATTERA 10MG\n",
              "...             ...     ...  ...                        ...                 ...\n",
              "133769  99207046730       1  ...  MC_COOKED_CALIBRATED_V1.2  SOLODYN 105 MG TAB\n",
              "133770  99207046730       1  ...  MC_COOKED_CALIBRATED_V1.2  SOLODYN 105 MG TAB\n",
              "133771  99207046730       1  ...  MC_COOKED_CALIBRATED_V1.2  SOLODYN 105 MG TAB\n",
              "133772  99207046730       1  ...  MC_COOKED_CALIBRATED_V1.2  SOLODYN 105 MG TAB\n",
              "133773  99207046730       1  ...       MC_SPL_SPLIMAGE_V3.0  SOLODYN 105 MG TAB\n",
              "\n",
              "[133774 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "typdict = {'NDC':'str'}\n",
        "df = pd.read_csv('/content/drive/My Drive/RxID2/directory_of_images.txt',sep='|', dtype=typdict, names=['NDC','PART_#','FILE','TYPE','DRUG'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kBNa7tVv733j"
      },
      "outputs": [],
      "source": [
        "ndcs = [    \n",
        "'00009033102',    \n",
        "'65862019430',\n",
        "'00591084510',\n",
        "'55111068305',\n",
        "'00527134410',\n",
        "'00093005801',    \n",
        "'45802091987',\n",
        "'61958070101',\n",
        "'49884003501',\n",
        "'00591078005',\n",
        "'31722020701',\n",
        "'68180047901',\n",
        "'65862007701',\n",
        "'00054472825',\n",
        "'68180040301'\n",
        "]\n",
        "ndcs_pack = [x[:-2] for x in ndcs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "piLNBSJm70Ij"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()\n",
        "df.DRUG = df.DRUG.str.upper()\n",
        "df[['ORIG_FOLDER','IMAGES','FILENAME']] = df.FILE.str.split('/', expand=True)\n",
        "df['FILETYPE'] = df.FILENAME.str[-4:]\n",
        "df = df[df.FILETYPE != '.WMV']# will remove video files from query\n",
        "df['NDC_prod'] = df.NDC.str[:-2]\n",
        "df = df[df.NDC_prod.isin(ndcs_pack)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0Op8bAsJzp-Z"
      },
      "outputs": [],
      "source": [
        "df.NDC[df.NDC == '00093005805'] = '00093005801'\n",
        "\n",
        "df.DRUG[df.NDC == '00093005801'] = 'LEVOTHYROXINE 0.088MG'\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p-pnDkpAzp8B"
      },
      "outputs": [],
      "source": [
        "df.DRUG.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IY2hXIjr6L-X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "colab_type": "code",
        "id": "WiZ8k0QwKeVf",
        "outputId": "7b7e7659-89bf-4caf-f6e9-f9caa575c963"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NDC</th>\n",
              "      <th>IDK</th>\n",
              "      <th>FILE</th>\n",
              "      <th>TYPE</th>\n",
              "      <th>DRUG</th>\n",
              "      <th>ORIG_FOLDER</th>\n",
              "      <th>IMAGES</th>\n",
              "      <th>FILENAME</th>\n",
              "      <th>FILETYPE</th>\n",
              "      <th>NDC_prod</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>00009033102</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc58/images/CB4CEJKI72-2IAAF8SPNK...</td>\n",
              "      <td>C3PI_Reference</td>\n",
              "      <td>CLEOCIN 75MG</td>\n",
              "      <td>PillProjectDisc58</td>\n",
              "      <td>images</td>\n",
              "      <td>CB4CEJKI72-2IAAF8SPNK-YD6QHSBHE.JPG</td>\n",
              "      <td>.CR2</td>\n",
              "      <td>000090331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2947</th>\n",
              "      <td>00009033102</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc95/images/MJ8SIXGLA!IDK6QKOJQ8N...</td>\n",
              "      <td>C3PI_Reference</td>\n",
              "      <td>CLEOCIN 75MG</td>\n",
              "      <td>PillProjectDisc95</td>\n",
              "      <td>images</td>\n",
              "      <td>MJ8SIXGLA!IDK6QKOJQ8N5DOBZIKHE.JPG</td>\n",
              "      <td>.CR2</td>\n",
              "      <td>000090331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949</th>\n",
              "      <td>00009033102</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc107/images/XW27OGQ!GSTCS6SVCFSE...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>CLEOCIN 75MG</td>\n",
              "      <td>PillProjectDisc107</td>\n",
              "      <td>images</td>\n",
              "      <td>XW27OGQ!GSTCS6SVCFSE6F!WHA7PYT.JPG</td>\n",
              "      <td>.JPG</td>\n",
              "      <td>000090331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2950</th>\n",
              "      <td>00009033102</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc13/images/9CLLUNVVKAJ4Y!Q0R_4_H...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>CLEOCIN 75MG</td>\n",
              "      <td>PillProjectDisc13</td>\n",
              "      <td>images</td>\n",
              "      <td>9CLLUNVVKAJ4Y!Q0R_4_H0I4EVZG5C.JPG</td>\n",
              "      <td>.JPG</td>\n",
              "      <td>000090331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2951</th>\n",
              "      <td>00009033102</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc17/images/B18QCJP3ZMIWFPGXJZ4R3...</td>\n",
              "      <td>C3PI_Test</td>\n",
              "      <td>CLEOCIN 75MG</td>\n",
              "      <td>PillProjectDisc17</td>\n",
              "      <td>images</td>\n",
              "      <td>B18QCJP3ZMIWFPGXJZ4R3I-OL2GR6Z-.JPG</td>\n",
              "      <td>.JPG</td>\n",
              "      <td>000090331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127776</th>\n",
              "      <td>68180047901</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc42/images/BP4V9ZT0LMIB4BO872E-W...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SIMVASTATIN</td>\n",
              "      <td>PillProjectDisc42</td>\n",
              "      <td>images</td>\n",
              "      <td>BP4V9ZT0LMIB4BO872E-WK025340X84.JPG</td>\n",
              "      <td>.PNG</td>\n",
              "      <td>681800479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127777</th>\n",
              "      <td>68180047901</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc51/images/BXRU3YZEHJU82Z4XML43I...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SIMVASTATIN</td>\n",
              "      <td>PillProjectDisc51</td>\n",
              "      <td>images</td>\n",
              "      <td>BXRU3YZEHJU82Z4XML43IK7X1JWYWH7.JPG</td>\n",
              "      <td>.PNG</td>\n",
              "      <td>681800479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127778</th>\n",
              "      <td>68180047901</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc72/images/CN_3M1A3P5IO95ONJAKUI...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SIMVASTATIN</td>\n",
              "      <td>PillProjectDisc72</td>\n",
              "      <td>images</td>\n",
              "      <td>CN_3M1A3P5IO95ONJAKUIFJYQC18Y9_.JPG</td>\n",
              "      <td>.PNG</td>\n",
              "      <td>681800479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127779</th>\n",
              "      <td>68180047901</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc83/images/CY8E7A05V71HWIUH2IQOZ...</td>\n",
              "      <td>MC_COOKED_CALIBRATED_V1.2</td>\n",
              "      <td>SIMVASTATIN</td>\n",
              "      <td>PillProjectDisc83</td>\n",
              "      <td>images</td>\n",
              "      <td>CY8E7A05V71HWIUH2IQOZYMM-2BJSD8.JPG</td>\n",
              "      <td>.PNG</td>\n",
              "      <td>681800479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127780</th>\n",
              "      <td>68180047901</td>\n",
              "      <td>1</td>\n",
              "      <td>PillProjectDisc2/images/-D0ICD37VEPDJZ5ZNLB4WS...</td>\n",
              "      <td>MC_SPL_SPLIMAGE_V3.0</td>\n",
              "      <td>SIMVASTATIN</td>\n",
              "      <td>PillProjectDisc2</td>\n",
              "      <td>images</td>\n",
              "      <td>-D0ICD37VEPDJZ5ZNLB4WSHBEP_TUD.JPG</td>\n",
              "      <td>.JPG</td>\n",
              "      <td>681800479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>607 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                NDC  IDK  ... FILETYPE   NDC_prod\n",
              "2946    00009033102    1  ...     .CR2  000090331\n",
              "2947    00009033102    1  ...     .CR2  000090331\n",
              "2949    00009033102    1  ...     .JPG  000090331\n",
              "2950    00009033102    1  ...     .JPG  000090331\n",
              "2951    00009033102    1  ...     .JPG  000090331\n",
              "...             ...  ...  ...      ...        ...\n",
              "127776  68180047901    1  ...     .PNG  681800479\n",
              "127777  68180047901    1  ...     .PNG  681800479\n",
              "127778  68180047901    1  ...     .PNG  681800479\n",
              "127779  68180047901    1  ...     .PNG  681800479\n",
              "127780  68180047901    1  ...     .JPG  681800479\n",
              "\n",
              "[607 rows x 10 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OIP1pl2bKeVg"
      },
      "outputs": [],
      "source": [
        "df.to_csv('../Data/rxid15.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eUVXmLcOzWBk"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AG7Gj20RZc0u"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Data/rxid15.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6SL58wXXHCIH"
      },
      "outputs": [],
      "source": [
        "train_folder = './RxID2_split/train'\n",
        "val_folder = './RxID2_split/validation'\n",
        "realworld_folder = './RxID2_split/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "HjJADoEdJk9s",
        "outputId": "cd3baee5-e9fb-43bd-bbed-59ed2b4e42a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 70 images belonging to 15 classes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 297 images belonging to 15 classes.\n",
            "Found 69 images belonging to 15 classes.\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 16\n",
        "IMG_SHAPE  = 28 \n",
        "EPOCHS = 50\n",
        "\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_folder,\n",
        "                                                                       shuffle=False,\n",
        "                                                                       #class_mode='binary',\n",
        "                                                                       target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                       batch_size = BATCH_SIZE,\n",
        "                                                                       classes = [cls for cls in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, cls))][:15])\n",
        "\n",
        "train_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    ).flow_from_directory(train_folder,\n",
        "                                                                          shuffle=True,\n",
        "                                                                   #class_mode='binary',\n",
        "                                                                          target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                          batch_size=BATCH_SIZE,\n",
        "                                                                          classes=[cls for cls in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, cls))][:15])\n",
        "\n",
        "realworld_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(realworld_folder,\n",
        "                                                                       shuffle=False,\n",
        "                                                                       class_mode='categorical',\n",
        "                                                                       target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                                       batch_size = BATCH_SIZE,\n",
        "                                                                       classes=[cls for cls in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, cls))][:15])\n",
        "# labels = list((val_generator.class_indices).values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ax1THVAb6NnS"
      },
      "source": [
        "## Matching Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uPzjtoLN7IZo"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "colab_type": "code",
        "id": "W6S-YiWmZc02",
        "outputId": "a8602d37-056b-4fc9-f852-ba6ad1204756"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m input_shape \u001b[39m=\u001b[39m (IMG_SHAPE, IMG_SHAPE, \u001b[39m3\u001b[39m)  \u001b[39m# Change this to the shape of your images\u001b[39;00m\n\u001b[0;32m     38\u001b[0m embedding \u001b[39m=\u001b[39m embedding_model(input_shape)\n\u001b[1;32m---> 39\u001b[0m support_set_images \u001b[39m=\u001b[39m x_train[:\u001b[39m20\u001b[39m]  \u001b[39m# Choose 20 images as the support set\u001b[39;00m\n\u001b[0;32m     40\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m\n\u001b[0;32m     42\u001b[0m matching_network \u001b[39m=\u001b[39m MatchingNetwork(support_set_images, num_classes, embedding)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Lambda, Conv2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming each batch has a set of support samples and a single query sample\n",
        "# N is the number of support samples per class\n",
        "N = 5\n",
        "\n",
        "# Support and query inputs\n",
        "support_input = Input(shape=(15*N, IMG_SHAPE, IMG_SHAPE, 3), name=\"support_input\")\n",
        "query_input = Input(shape=(IMG_SHAPE, IMG_SHAPE, 3), name=\"query_input\")\n",
        "\n",
        "# Embedding function (using the CNN structure you provided)\n",
        "def embed_model(input_shape):\n",
        "    model = models.Sequential(name='embedding_model')\n",
        "    model.add(layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((3, 3)))\n",
        "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(layers.Flatten())\n",
        "    return model\n",
        "\n",
        "# Getting embeddings for support and query sets\n",
        "embed = embed_model((IMG_SHAPE, IMG_SHAPE, 3))\n",
        "support_embeddings = embed(support_input)\n",
        "query_embedding = embed(query_input)\n",
        "\n",
        "# Cosine similarity between the support and query embeddings\n",
        "def cosine_similarity(a, b):\n",
        "    normalize_a = tf.nn.l2_normalize(a, axis=-1)\n",
        "    normalize_b = tf.nn.l2_normalize(b, axis=-1)\n",
        "    cos_similarity = tf.reduce_sum(tf.multiply(normalize_a, normalize_b), axis=-1)\n",
        "    return cos_similarity\n",
        "\n",
        "# Computing the similarities and predictions\n",
        "similarities = Lambda(lambda x: cosine_similarity(x[0], x[1]))([support_embeddings, query_embedding])\n",
        "weights = tf.nn.softmax(similarities)\n",
        "predictions = Lambda(lambda x: tf.matmul(tf.expand_dims(x[0], axis=1), x[1]))([weights, support_embeddings])\n",
        "\n",
        "# Building the final model\n",
        "matching_model = Model(inputs=[support_input, query_input], outputs=predictions)\n",
        "matching_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "matching_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8v8o-ZWS7MrF"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HWOM1Xi8Zc04"
      },
      "outputs": [],
      "source": [
        "history = matching_network.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[early,csv_logger],\n",
        "                    # use_multiprocessing=True,\n",
        "                    # workers=multiprocessing.cpu_count(),\n",
        "                    verbose=2)\n",
        "matching_network.save('../Data/Models/model_{}'.format(matching_network.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4JnsFQ8Zc05"
      },
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "ui_FTOn-mJHu",
        "outputId": "58d688b9-d3ae-49ad-c513-832723a90150"
      },
      "outputs": [],
      "source": [
        "hist = pd.read_csv('../Data/Models/hist_{}.log'.format(matching_network.name), sep=',', engine='python')\n",
        "\n",
        "model_scores(matching_network)\n",
        "\n",
        "real_world_predicts(matching_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "colab_type": "code",
        "id": "Mvw9ut4en-dN",
        "outputId": "26bbf55b-750d-4aba-a86e-6d3210fe2eca"
      },
      "outputs": [],
      "source": [
        "model_acc_val_plot(matching_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "colab_type": "code",
        "id": "CGD4Mo7Wn_rr",
        "outputId": "ee36e976-d0a9-4cc3-bc5e-156efa285cff"
      },
      "outputs": [],
      "source": [
        "model_confusion(matching_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "colab_type": "code",
        "id": "lEY4KCebn_x5",
        "outputId": "244544a8-639a-4cb0-e6b2-83b511bdb011"
      },
      "outputs": [],
      "source": [
        "predict_plot(matching_network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Siamese Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
        "\n",
        "# Define the embedding model\n",
        "def embedding_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Conv2D(128, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((3, 3)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
        "        Flatten()\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the Euclidean distance function\n",
        "def euclidean_distance(vectors):\n",
        "    x, y = vectors\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "# Assume `input_shape` is the shape of your images\n",
        "input_shape = (IMG_SHAPE, IMG_SHAPE, 3)\n",
        "base_network = embedding_model(input_shape)\n",
        "\n",
        "# Create the left input and point to the base network\n",
        "input_a = Input(shape=input_shape)\n",
        "vect_output_a = base_network(input_a)\n",
        "\n",
        "# Create the right input and point to the base network\n",
        "input_b = Input(shape=input_shape)\n",
        "vect_output_b = base_network(input_b)\n",
        "\n",
        "# Measure the similarity of the two vector outputs\n",
        "output = Lambda(euclidean_distance)([vect_output_a, vect_output_b])\n",
        "\n",
        "# Specify the model\n",
        "siamese_model = Model([input_a, input_b], output)\n",
        "\n",
        "# Compile the model\n",
        "siamese_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# Set the callbacks\n",
        "csv_logger = CSVLogger('../Data/Models/hist_{}.log'.format(model.name), separator=',', append=False)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "# Train the model\n",
        "siamese_model.fit([x_train_1, x_train_2], y_train, epochs=10, callbacks=[csv_logger, early])\n",
        "\n",
        "# Evaluate the siamese_model\n",
        "test_loss, test_acc = siamese_model.evaluate([x_test_1, x_test_2], y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = siamese_model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[early,csv_logger],\n",
        "                    # use_multiprocessing=True,\n",
        "                    # workers=multiprocessing.cpu_count(),\n",
        "                    verbose=2)\n",
        "siamese_model.save('../Data/Models/model_{}'.format(siamese_model.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = pd.read_csv('../Data/Models/hist_{}.log'.format(siamese_model.name), sep=',', engine='python')\n",
        "\n",
        "model_scores(siamese_model)\n",
        "\n",
        "real_world_predicts(siamese_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_acc_val_plot(siamese_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_confusion(siamese_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_plot(siamese_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relational Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
        "\n",
        "# Define the object processing model\n",
        "def object_processing_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Conv2D(128, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((3, 3)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the relation processing model\n",
        "def relation_processing_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(15, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Assume `input_shape` is the shape of your images\n",
        "input_shape = (IMG_SHAPE, IMG_SHAPE, 3)\n",
        "object_model = object_processing_model(input_shape)\n",
        "\n",
        "# Create the two inputs and process them through the object model\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "processed_a = object_model(input_a)\n",
        "processed_b = object_model(input_b)\n",
        "\n",
        "# Concatenate the processed objects and feed them to the relation model\n",
        "concatenated = Concatenate(axis=-1)([processed_a, processed_b])\n",
        "relation_model = relation_processing_model()\n",
        "output = relation_model(concatenated)\n",
        "\n",
        "# Specify the model\n",
        "relational_model = Model([input_a, input_b], output)\n",
        "\n",
        "# Compile the model\n",
        "relational_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Set the callbacks\n",
        "csv_logger = CSVLogger('../Data/Models/hist_{}.log'.format(relational_model.name), separator=',', append=False)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "# Train the model\n",
        "relational_model.fit([x_train_1, x_train_2], y_train, epochs=10, callbacks=[csv_logger, early])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = relational_model.evaluate([x_test_1, x_test_2], y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = relational_model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[early,csv_logger],\n",
        "                    # use_multiprocessing=True,\n",
        "                    # workers=multiprocessing.cpu_count(),\n",
        "                    verbose=2)\n",
        "relational_model.save('../Data/Models/model_{}'.format(relational_model.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = pd.read_csv('../Data/Models/hist_{}.log'.format(relational_model.name), sep=',', engine='python')\n",
        "\n",
        "model_scores(relational_model)\n",
        "\n",
        "real_world_predicts(relational_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_acc_val_plot(relational_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_confusion(relational_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_plot(relational_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNS4BRTR9iYqXExwM8CmiUl",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "RxVision_Technical_Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "4d32610e65d0ba547d20b5ddccd11b31c7d91644470808fb362c82b58c120951"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
